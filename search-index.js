var searchIndex = {};
searchIndex["ovr_sys"] = {"doc":"This crate provides raw unsafe bindings to LibOVR, the Oculus Rift runtime library.","items":[[3,"ovrErrorInfo","ovr_sys","Provides information about the last error.",null,null],[12,"Result","","The result from the last API call that generated an error `ovrResult`.",0,null],[12,"ErrorString","","A UTF8-encoded null-terminated English string describing the problem. The format of this string is subject to change in future versions.",0,null],[3,"ovrColorf","","A RGBA color with normalized `f32` components.",null,null],[12,"_align","","",1,null],[12,"r","","",1,null],[12,"g","","",1,null],[12,"b","","",1,null],[12,"a","","",1,null],[3,"ovrVector2i","","A 2D vector with integer components.",null,null],[12,"_align","","",2,null],[12,"x","","",2,null],[12,"y","","",2,null],[3,"ovrSizei","","A 2D size with integer components.",null,null],[12,"_align","","",3,null],[12,"w","","",3,null],[12,"h","","",3,null],[3,"ovrRecti","","A 2D rectangle with a position and size. All components are integers.",null,null],[12,"_align","","",4,null],[12,"Pos","","",4,null],[12,"Size","","",4,null],[3,"ovrQuatf","","A quaternion rotation.",null,null],[12,"_align","","",5,null],[12,"x","","",5,null],[12,"y","","",5,null],[12,"z","","",5,null],[12,"w","","",5,null],[3,"ovrVector2f","","A 2D vector with `f32` components.",null,null],[12,"_align","","",6,null],[12,"x","","",6,null],[12,"y","","",6,null],[3,"ovrVector3f","","A 3D vector with `f32` components.",null,null],[12,"_align","","",7,null],[12,"x","","",7,null],[12,"y","","",7,null],[12,"z","","",7,null],[3,"ovrMatrix4f","","A 4x4 matrix with `f32` elements.",null,null],[12,"_align","","",8,null],[3,"ovrPosef","","Position and orientation together.",null,null],[12,"_align","","",9,null],[12,"Orientation","","",9,null],[12,"Position","","",9,null],[3,"ovrPoseStatef","","A full pose (rigid body) configuration with first and second derivatives.",null,null],[12,"_align","","",10,null],[12,"ThePose","","Position and orientation.",10,null],[12,"AngularVelocity","","Angular velocity in radians per second.",10,null],[12,"LinearVelocity","","Velocity in meters per second.",10,null],[12,"AngularAcceleration","","Angular acceleration in radians per second per second.",10,null],[12,"LinearAcceleration","","Acceleration in meters per second per second.",10,null],[12,"_pad0","","\\internal struct pad.",10,null],[12,"TimeInSeconds","","Absolute time that this pose refers to. see  `ovr_GetTimeInSeconds`",10,null],[3,"ovrFovPort","","Describes the up, down, left, and right angles of the field of view.",null,null],[12,"_align","","",11,null],[12,"UpTan","","The tangent of the angle between the viewing vector and the top edge of the field of view.",11,null],[12,"DownTan","","The tangent of the angle between the viewing vector and the bottom edge of the field of view.",11,null],[12,"LeftTan","","The tangent of the angle between the viewing vector and the left edge of the field of view.",11,null],[12,"RightTan","","The tangent of the angle between the viewing vector and the right edge of the field of view.",11,null],[3,"ovrGraphicsLuid","","Identifies a graphics device in a platform-specific way. For Windows this is a LUID type.",null,null],[12,"_align","","",12,null],[12,"Reserved","","Public definition reserves space for graphics API-specific implementation",12,null],[3,"ovrHmdDesc","","This is a complete descriptor of the HMD.",null,null],[12,"_align","","",13,null],[12,"Type","","The type of HMD.",13,null],[12,"_pad0","","\\internal struct paddding.",13,null],[12,"ProductName","","UTF8-encoded product identification string (e.g. \"Oculus Rift DK1\").",13,null],[12,"Manufacturer","","UTF8-encoded HMD manufacturer identification string.",13,null],[12,"VendorId","","HID (USB) vendor identifier of the device.",13,null],[12,"ProductId","","HID (USB) product identifier of the device.",13,null],[12,"SerialNumber","","HMD serial number.",13,null],[12,"FirmwareMajor","","HMD firmware major version.",13,null],[12,"FirmwareMinor","","HMD firmware minor version.",13,null],[12,"AvailableHmdCaps","","Capability bits described by `ovrHmdCaps` which the HMD currently supports.",13,null],[12,"DefaultHmdCaps","","Capability bits described by `ovrHmdCaps` which are default for the current Hmd.",13,null],[12,"AvailableTrackingCaps","","Capability bits described by `ovrTrackingCaps` which the system currently supports.",13,null],[12,"DefaultTrackingCaps","","Capability bits described by `ovrTrackingCaps` which are default for the current system.",13,null],[12,"DefaultEyeFov","","Defines the recommended FOVs for the HMD.",13,null],[12,"MaxEyeFov","","Defines the maximum FOVs for the HMD.",13,null],[12,"Resolution","","Resolution of the full HMD screen (both eyes) in pixels.",13,null],[12,"DisplayRefreshRate","","Nominal refresh rate of the display in cycles per second at the time of HMD creation.",13,null],[12,"_pad1","","\\internal struct paddding.",13,null],[3,"ovrTrackerDesc","","Specifies the description of a single sensor.",null,null],[12,"_align","","",14,null],[12,"FrustumHFovInRadians","","Sensor frustum horizontal field-of-view (if present).",14,null],[12,"FrustumVFovInRadians","","Sensor frustum vertical field-of-view (if present).",14,null],[12,"FrustumNearZInMeters","","Sensor frustum near Z (if present).",14,null],[12,"FrustumFarZInMeters","","Sensor frustum far Z (if present).",14,null],[3,"ovrTrackerPose","","Specifies the pose for a single sensor.",null,null],[12,"_align","","",15,null],[12,"TrackerFlags","","`ovrTrackerFlags`.",15,null],[12,"Pose","","The sensor's pose. This pose includes sensor tilt (roll and pitch). For a leveled coordinate system use LeveledPose.",15,null],[12,"LeveledPose","","The sensor's leveled pose, aligned with gravity. This value includes position and yaw of the sensor, but not roll and pitch. It can be used as a reference point to render real-world objects in the correct location.",15,null],[12,"_pad0","","\\internal struct pad.",15,null],[3,"ovrTrackingState","","Tracking state at a given absolute time (describes predicted HMD pose, etc.). Returned by  `ovr_GetTrackingState`.",null,null],[12,"_align","","",16,null],[12,"HeadPose","","Predicted head pose (and derivatives) at the requested absolute time.",16,null],[12,"StatusFlags","","HeadPose tracking status described by `ovrStatusBits`.",16,null],[12,"HandPoses","","The most recent calculated pose for each hand when hand controller tracking is present. HandPoses[`ovrHand_Left` as usize] refers to the left hand and HandPoses[`ovrHand_Right` as usize] to the right hand. These values can be combined with `ovrInputState` for complete hand controller information.",16,null],[12,"HandStatusFlags","","HandPoses status flags described by `ovrStatusBits`. Only `ovrStatus_OrientationTracked` and `ovrStatus_PositionTracked` are reported.",16,null],[12,"CalibratedOrigin","","The pose of the origin captured during calibration. Like all other poses here, this is expressed in the space set by `ovr_RecenterTrackingOrigin`, or `ovr_SpecifyTrackingOrigin` and so will change every time either of those functions are called. This pose can be used to calculate where the calibrated origin lands in the new recentered space. If an application never calls `ovr_RecenterTrackingOrigin` or `ovr_SpecifyTrackingOrigin`, expect this value to be the identity pose and as such will point respective origin based on `ovrTrackingOrigin` requested when calling `ovr_GetTrackingState`.",16,null],[3,"ovrEyeRenderDesc","","Rendering information for each eye. Computed by  `ovr_GetRenderDesc()` based on the specified FOV. Note that the rendering viewport is not included here as it can be specified separately and modified per frame by passing different Viewport values in the layer structure.",null,null],[12,"_align","","",17,null],[12,"Eye","","The eye index to which this instance corresponds.",17,null],[12,"Fov","","The field of view.",17,null],[12,"DistortedViewport","","Distortion viewport.",17,null],[12,"PixelsPerTanAngleAtCenter","","How many display pixels will fit in tan(angle) = 1.",17,null],[12,"HmdToEyeOffset","","Translation of each eye, in meters.",17,null],[3,"ovrTimewarpProjectionDesc","","Projection information for `ovrLayerEyeFovDepth`.",null,null],[12,"_align","","",18,null],[12,"Projection22","","Projection matrix element [2][2].",18,null],[12,"Projection23","","Projection matrix element [2][3].",18,null],[12,"Projection32","","Projection matrix element [3][2].",18,null],[3,"ovrViewScaleDesc","","Contains the data necessary to properly calculate position info for various layer types.",null,null],[12,"_align","","",19,null],[12,"HmdToEyeOffset","","Translation of each eye.",19,null],[12,"HmdSpaceToWorldScaleInMeters","","Ratio of viewer units to meter units.",19,null],[3,"ovrTextureSwapChainDesc","","Description used to create a texture swap chain.",null,null],[12,"Type","","",20,null],[12,"Format","","",20,null],[12,"ArraySize","","Only supported with `ovrTexture_2D`. Not supported on PC at this time.",20,null],[12,"Width","","",20,null],[12,"Height","","",20,null],[12,"MipLevels","","",20,null],[12,"SampleCount","","Current only supported on depth textures",20,null],[12,"StaticImage","","Not buffered in a chain. For images that don't change",20,null],[12,"MiscFlags","","`ovrTextureFlags`",20,null],[12,"BindFlags","","`ovrTextureBindFlags`. Not used for GL.",20,null],[3,"ovrMirrorTextureDesc","","Description used to create a mirror texture.",null,null],[12,"Format","","",21,null],[12,"Width","","",21,null],[12,"Height","","",21,null],[12,"MiscFlags","","`ovrTextureFlags`",21,null],[3,"ovrTouchHapticsDesc","","Describes the Touch Haptics engine. Currently, those values will NOT change during a session.",null,null],[12,"_align","","",22,null],[12,"SampleRateHz","","Haptics engine frequency/sample-rate, sample time in seconds equals 1.0/sampleRateHz",22,null],[12,"SampleSizeInBytes","","Size of each Haptics sample, sample value range is `[0, 2^(Bytes*8)-1]`",22,null],[12,"QueueMinSizeToAvoidStarvation","","Queue size that would guarantee Haptics engine would not starve for data Make sure size doesn't drop below it for best results",22,null],[12,"SubmitMinSamples","","Minimum, Maximum and Optimal number of samples that can be sent to Haptics through  `ovr_SubmitControllerVibration`",22,null],[12,"SubmitMaxSamples","","",22,null],[12,"SubmitOptimalSamples","","",22,null],[3,"ovrHapticsBuffer","","Haptics buffer descriptor, contains amplitude samples used for Touch vibration",null,null],[12,"Samples","","Samples stored in opaque format",23,null],[12,"SamplesCount","","Number of samples",23,null],[12,"SubmitMode","","How samples are submitted to the hardware",23,null],[3,"ovrHapticsPlaybackState","","State of the Haptics playback for Touch vibration",null,null],[12,"RemainingQueueSpace","","Remaining space available to queue more samples",24,null],[12,"SamplesQueued","","Number of samples currently queued",24,null],[3,"ovrBoundaryLookAndFeel","","Boundary system look and feel",null,null],[12,"Color","","Boundary color (alpha channel is ignored)",25,null],[3,"ovrBoundaryTestResult","","Provides boundary test information",null,null],[12,"IsTriggering","","True if the boundary system is being triggered. Note that due to fade in/out effects this may not exactly match visibility.",26,null],[12,"ClosestDistance","","Distance to the closest play area or outer boundary surface.",26,null],[12,"ClosestPoint","","Closest point on the boundary surface.",26,null],[12,"ClosestPointNormal","","Unit surface normal of the closest boundary surface.",26,null],[3,"ovrInputState","","`ovrInputState` describes the complete controller input state, including Oculus Touch, and XBox gamepad. If multiple inputs are connected and used at the same time, their inputs are combined.",null,null],[12,"TimeInSeconds","","System type when the controller state was last updated.",27,null],[12,"Buttons","","Values for buttons described by `ovrButton`.",27,null],[12,"Touches","","Touch values for buttons and sensors as described by `ovrTouch`.",27,null],[12,"IndexTrigger","","Left and right finger trigger values (`ovrHand_Left` and `ovrHand_Right`), in the range 0.0 to 1.0f. Returns 0 if the value would otherwise be less than 0.1176, for `ovrControllerType_XBox`. This has been formally named simply \"Trigger\". We retain the name IndexTrigger for backwards code compatibility. User-facing documentation should refer to it as the Trigger.",27,null],[12,"HandTrigger","","Left and right hand trigger values (`ovrHand_Left` and `ovrHand_Right`), in the range 0.0 to 1.0f. This has been formally named \"Grip Button\". We retain the name HandTrigger for backwards code compatibility. User-facing documentation should refer to it as the Grip Button or simply Grip.",27,null],[12,"Thumbstick","","Horizontal and vertical thumbstick axis values (`ovrHand_Left` and `ovrHand_Right`), in the range -1.0f to 1.0f. Returns a deadzone (value 0) per each axis if the value on that axis would otherwise have been between -.2746 to +.2746, for `ovrControllerType_XBox`",27,null],[12,"ControllerType","","The type of the controller this state is for.",27,null],[12,"IndexTriggerNoDeadzone","","Left and right finger trigger values (`ovrHand_Left` and `ovrHand_Right`), in the range 0.0 to 1.0f. Does not apply a deadzone.  Only touch applies a filter. This has been formally named simply \"Trigger\". We retain the name IndexTrigger for backwards code compatibility. User-facing documentation should refer to it as the Trigger. Added in 1.7",27,null],[12,"HandTriggerNoDeadzone","","Left and right hand trigger values (`ovrHand_Left` and `ovrHand_Right`), in the range 0.0 to 1.0f. Does not apply a deadzone. Only touch applies a filter. This has been formally named \"Grip Button\". We retain the name HandTrigger for backwards code compatibility. User-facing documentation should refer to it as the Grip Button or simply Grip. Added in 1.7",27,null],[12,"ThumbstickNoDeadzone","","Horizontal and vertical thumbstick axis values (`ovrHand_Left` and `ovrHand_Right`), in the range -1.0f to 1.0f Does not apply a deadzone or filter. Added in 1.7",27,null],[12,"IndexTriggerRaw","","Left and right finger trigger values (`ovrHand_Left` and `ovrHand_Right`), in range 0.0 to 1.0f. No deadzone or filter This has been formally named \"Grip Button\". We retain the name HandTrigger for backwards code compatibility. User-facing documentation should refer to it as the Grip Button or simply Grip.",27,null],[12,"HandTriggerRaw","","Left and right hand trigger values (`ovrHand_Left` and `ovrHand_Right`), in the range 0.0 to 1.0f. No deadzone or filter This has been formally named \"Grip Button\". We retain the name HandTrigger for backwards code compatibility. User-facing documentation should refer to it as the Grip Button or simply Grip.",27,null],[12,"ThumbstickRaw","","Horizontal and vertical thumbstick axis values (`ovrHand_Left` and `ovrHand_Right`), in the range -1.0f to 1.0f No deadzone or filter",27,null],[3,"ovrInitParams","","Parameters for  `ovr_Initialize`.",null,null],[12,"_align","","",28,null],[12,"Flags","","Flags from `ovrInitFlags` to override default behavior. Use 0 for the defaults.",28,null],[12,"RequestedMinorVersion","","Requests a specific minor version of the LibOVR runtime. Flags must include `ovrInit_RequestVersion` or this will be ignored and  `OVR_MINOR_VERSION` will be used. If you are directly calling the LibOVRRT version of  `ovr_Initialize` in the LibOVRRT DLL then this must be valid and include `ovrInit_RequestVersion`.",28,null],[12,"LogCallback","","User-supplied log callback function, which may be called at any time asynchronously from multiple threads until  `ovr_Shutdown` completes. Use NULL to specify no log callback.",28,null],[12,"UserData","","User-supplied data which is passed as-is to LogCallback. Typically this is used to store an application-specific pointer which is read in the callback function.",28,null],[12,"ConnectionTimeoutMS","","Relative number of milliseconds to wait for a connection to the server before failing. Use 0 for the default timeout.",28,null],[12,"_pad0","","\\internal",28,null],[3,"ovrSessionStatus","","Specifies status information for the current session.",null,null],[12,"IsVisible","","True if the process has VR focus and thus is visible in the HMD.",29,null],[12,"HmdPresent","","True if an HMD is present.",29,null],[12,"HmdMounted","","True if the HMD is on the user's head.",29,null],[12,"DisplayLost","","True if the session is in a display-lost state. See  `ovr_SubmitFrame`.",29,null],[12,"ShouldQuit","","True if the application should initiate shutdown.",29,null],[12,"ShouldRecenter","","True if UX has requested re-centering. Must call `ovr_ClearShouldRecenterFlag`, `ovr_RecenterTrackingOrigin` or `ovr_SpecifyTrackingOrigin`.",29,null],[3,"ovrLayerHeader","","Defines properties shared by all `ovrLayer` structs, such as `ovrLayerEyeFov`.",null,null],[12,"_align","","",30,null],[12,"Type","","Described by `ovrLayerType`.",30,null],[12,"Flags","","Described by `ovrLayerFlags`.",30,null],[3,"ovrLayerEyeFov","","Describes a layer that specifies a monoscopic or stereoscopic view.",null,null],[12,"_align","","",31,null],[12,"Header","","Header.Type must be `ovrLayerType_EyeFov`.",31,null],[12,"ColorTexture","","`ovrTextureSwapChains` for the left and right eye respectively.",31,null],[12,"Viewport","","Specifies the ColorTexture sub-rect UV coordinates.",31,null],[12,"Fov","","The viewport field of view.",31,null],[12,"RenderPose","","Specifies the position and orientation of each eye view, with the position specified in meters.",31,null],[12,"SensorSampleTime","","Specifies the timestamp when the source `ovrPosef` (used in calculating RenderPose) was sampled from the SDK. Typically retrieved by calling `ovr_GetTimeInSeconds` around the instant the application calls `ovr_GetTrackingState` The main purpose for this is to accurately track app tracking latency.",31,null],[3,"ovrLayerEyeMatrix","","Describes a layer that specifies a monoscopic or stereoscopic view.",null,null],[12,"_align","","",32,null],[12,"Header","","Header.Type must be `ovrLayerType_EyeMatrix`.",32,null],[12,"ColorTexture","","`ovrTextureSwapChains` for the left and right eye respectively.",32,null],[12,"Viewport","","Specifies the ColorTexture sub-rect UV coordinates.",32,null],[12,"RenderPose","","Specifies the position and orientation of each eye view, with the position specified in meters.",32,null],[12,"Matrix","","Specifies the mapping from a view-space vector to a UV coordinate on the textures given above.",32,null],[12,"SensorSampleTime","","Specifies the timestamp when the source `ovrPosef` (used in calculating RenderPose) was sampled from the SDK. Typically retrieved by calling `ovr_GetTimeInSeconds` around the instant the application calls `ovr_GetTrackingState` The main purpose for this is to accurately track app tracking latency.",32,null],[3,"ovrLayerQuad","","Describes a layer of Quad type, which is a single quad in world or viewer space.",null,null],[12,"_align","","",33,null],[12,"Header","","Header.Type must be `ovrLayerType_Quad`.",33,null],[12,"ColorTexture","","Contains a single image, never with any stereo view.",33,null],[12,"Viewport","","Specifies the ColorTexture sub-rect UV coordinates.",33,null],[12,"QuadPoseCenter","","Specifies the orientation and position of the center point of a Quad layer type.",33,null],[12,"QuadSize","","Width and height (respectively) of the quad in meters.",33,null],[3,"ovrPerfStatsPerCompositorFrame","","",null,null],[12,"_align","","",34,null],[12,"HmdVsyncIndex","","",34,null],[12,"AppFrameIndex","","",34,null],[12,"AppDroppedFrameCount","","If the app fails to call `ovr_SubmitFrame` on time, then expect this value to increment with each missed frame",34,null],[12,"AppMotionToPhotonLatency","","Motion-to-photon latency for the application This value is calculated by either using the SensorSampleTime provided for the `ovrLayerEyeFov` or if that is not available, then the call to `ovr_GetTrackingState` which has latencyMarker set to `ovrTrue`",34,null],[12,"AppQueueAheadTime","","Amount of queue-ahead in seconds provided to the app based on performance and overlap of CPU & GPU utilization A value of 0.0 would mean the CPU & GPU workload is being completed in 1 frame's worth of time, while 11 ms (on the CV1) of queue ahead would indicate that the app's CPU workload for the next frame is overlapping the app's GPU workload for the current frame.",34,null],[12,"AppCpuElapsedTime","","Amount of time in seconds spent on the CPU by the app's render-thread that calls `ovr_SubmitFrame` Measured as elapsed time between from when app regains control from `ovr_SubmitFrame` to the next time the app calls `ovr_SubmitFrame`.",34,null],[12,"AppGpuElapsedTime","","Amount of time in seconds spent on the GPU by the app Measured as elapsed time between each `ovr_SubmitFrame` call using GPU timing queries.",34,null],[12,"CompositorFrameIndex","","",34,null],[12,"CompositorDroppedFrameCount","","Increments each time the SDK compositor fails to complete in time This is not tied to the app's performance, but failure to complete can be tied to other factors such as OS capabilities, overall available hardware cycles to execute the compositor in time and other factors outside of the app's control.",34,null],[12,"CompositorLatency","","Motion-to-photon latency of the SDK compositor in seconds This is the latency of timewarp which corrects the higher app latency as well as dropped app frames.",34,null],[12,"CompositorCpuElapsedTime","","The amount of time in seconds spent on the CPU by the SDK compositor. Unless the VR app is utilizing all of the CPU cores at their peak performance, there is a good chance the compositor CPU times will not affect the app's CPU performance in a major way.",34,null],[12,"CompositorGpuElapsedTime","","The amount of time in seconds spent on the GPU by the SDK compositor. Any time spent on the compositor will eat away from the available GPU time for the app.",34,null],[12,"CompositorCpuStartToGpuEndElapsedTime","","The amount of time in seconds spent from the point the CPU kicks off the compositor to the point in time the compositor completes the distortion & timewarp on the GPU. In the event the GPU time is not available, expect this value to be -1.0f",34,null],[12,"CompositorGpuEndToVsyncElapsedTime","","The amount of time in seconds left after the compositor is done on the GPU to the associated V-Sync time.",34,null],[3,"ovrPerfStats","","This is a complete descriptor of the performance stats provided by the SDK",null,null],[12,"_align","","",35,null],[12,"FrameStats","","",35,null],[12,"FrameStatsCount","","",35,null],[12,"AnyFrameStatsDropped","","",35,null],[12,"AdaptiveGpuPerformanceScale","","",35,null],[3,"ovrDetectResult","","Return values for `ovr_Detect`.",null,null],[12,"_align","","",36,null],[12,"IsOculusServiceRunning","","Is `ovrFalse` when the Oculus Service is not running.   This means that the Oculus Service is either uninstalled or stopped.   `IsOculusHMDConnected` will be `ovrFalse` in this case.",36,null],[12,"IsOculusHMDConnected","","Is `ovrFalse` when an Oculus HMD is not detected.   If the Oculus Service is not running, this will be `ovrFalse`.",36,null],[12,"_pad0","","\\internal struct pad.",36,null],[5,"OVR_SUCCESS","","Indicates if an `ovrResult` indicates success.",null,{"inputs":[{"name":"ovrresult"}],"output":{"name":"bool"}}],[5,"OVR_UNQUALIFIED_SUCCESS","","Indicates if an `ovrResult` indicates an unqualified success.",null,{"inputs":[{"name":"ovrresult"}],"output":{"name":"bool"}}],[5,"OVR_FAILURE","","Indicates if an `ovrResult` indicates failure.",null,{"inputs":[{"name":"ovrresult"}],"output":{"name":"bool"}}],[5,"ovr_Initialize","","Initializes LibOVR",null,null],[5,"ovr_Shutdown","","Shuts down LibOVR",null,null],[5,"ovr_GetLastErrorInfo","","Returns information about the most recent failed return value by the current thread for this library.",null,null],[5,"ovr_GetVersionString","","Returns the version string representing the LibOVRRT version.",null,null],[5,"ovr_TraceMessage","","Writes a message string to the LibOVR tracing mechanism (if enabled).",null,null],[5,"ovr_IdentifyClient","","Identify client application info.",null,null],[5,"ovr_GetHmdDesc","","Returns information about the current HMD.",null,null],[5,"ovr_GetTrackerCount","","Returns the number of attached trackers.",null,null],[5,"ovr_GetTrackerDesc","","Returns a given attached tracker description.",null,null],[5,"ovr_Create","","Creates a handle to a VR session.",null,null],[5,"ovr_Destroy","","Destroys the session.",null,null],[5,"ovr_GetSessionStatus","","Returns status information for the application.",null,null],[5,"ovr_SetTrackingOriginType","","Sets the tracking origin type",null,null],[5,"ovr_GetTrackingOriginType","","Gets the tracking origin state",null,null],[5,"ovr_RecenterTrackingOrigin","","Re-centers the sensor position and orientation.",null,null],[5,"ovr_SpecifyTrackingOrigin","","Allows manually tweaking the sensor position and orientation.",null,null],[5,"ovr_ClearShouldRecenterFlag","","Clears the ShouldRecenter status bit in `ovrSessionStatus`.",null,null],[5,"ovr_GetTrackingState","","Returns tracking state reading based on the specified absolute system time.",null,null],[5,"ovr_GetTrackerPose","","Returns the `ovrTrackerPose` for the given attached tracker.",null,null],[5,"ovr_GetInputState","","Returns the most recent input state for controllers, without positional tracking info.",null,null],[5,"ovr_GetConnectedControllerTypes","","Returns controller types connected to the system OR'ed together.",null,null],[5,"ovr_GetTouchHapticsDesc","","Gets information about Haptics engine for the specified Touch controller.",null,null],[5,"ovr_SetControllerVibration","","Sets constant vibration (with specified frequency and amplitude) to a controller.",null,null],[5,"ovr_SubmitControllerVibration","","Submits a Haptics buffer (used for vibration) to Touch (only) controllers.",null,null],[5,"ovr_GetControllerVibrationState","","Gets the Haptics engine playback state of a specific Touch controller.",null,null],[5,"ovr_TestBoundary","","Tests collision/proximity of position tracked devices (e.g. HMD and/or Touch) against the Boundary System. Note: this method is similar to `ovr_BoundaryTestPoint` but can be more precise as it may take into account device acceleration/momentum.",null,null],[5,"ovr_TestBoundaryPoint","","Tests collision/proximity of a 3D point against the Boundary System.",null,null],[5,"ovr_SetBoundaryLookAndFeel","","Sets the look and feel of the Boundary System.",null,null],[5,"ovr_ResetBoundaryLookAndFeel","","Resets the look and feel of the Boundary System to its default state.",null,null],[5,"ovr_GetBoundaryGeometry","","Gets the geometry of the Boundary System's \"play area\" or \"outer boundary\" as 3D floor points.",null,null],[5,"ovr_GetBoundaryDimensions","","Gets the dimension of the Boundary System's \"play area\" or \"outer boundary\".",null,null],[5,"ovr_GetBoundaryVisible","","Returns if the boundary is currently visible. Note: visibility is false if the user has turned off boundaries, otherwise, it's true if the app has requested boundaries to be visible or if any tracked device is currently triggering it. This may not exactly match rendering due to fade-in and fade-out effects.",null,null],[5,"ovr_RequestBoundaryVisible","","Requests boundary to be visible.",null,null],[5,"ovr_GetTextureSwapChainLength","","TextureSwapChain creation is rendering API-specific.",null,null],[5,"ovr_GetTextureSwapChainCurrentIndex","","Gets the current index in an `ovrTextureSwapChain`.",null,null],[5,"ovr_GetTextureSwapChainDesc","","Gets the description of the buffers in an `ovrTextureSwapChain`",null,null],[5,"ovr_CommitTextureSwapChain","","Commits any pending changes to an `ovrTextureSwapChain`, and advances its current index",null,null],[5,"ovr_DestroyTextureSwapChain","","Destroys an `ovrTextureSwapChain` and frees all the resources associated with it.",null,null],[5,"ovr_DestroyMirrorTexture","","MirrorTexture creation is rendering API-specific.",null,null],[5,"ovr_GetFovTextureSize","","Calculates the recommended viewport size for rendering a given eye within the HMD with a given FOV cone.",null,null],[5,"ovr_GetRenderDesc","","Computes the distortion viewport, view adjust, and other rendering parameters for the specified eye.",null,null],[5,"ovr_SubmitFrame","","Submits layers for distortion and display.",null,null],[5,"ovr_GetPerfStats","","Retrieves performance stats for the VR app as well as the SDK compositor.",null,null],[5,"ovr_ResetPerfStats","","Resets the accumulated stats reported in each `ovrPerfStatsPerCompositorFrame` back to zero.",null,null],[5,"ovr_GetPredictedDisplayTime","","Gets the time of the specified frame midpoint.",null,null],[5,"ovr_GetTimeInSeconds","","Returns global, absolute high-resolution time in seconds.",null,null],[5,"ovr_GetBool","","Reads a boolean property.",null,null],[5,"ovr_SetBool","","Writes or creates a boolean property.",null,null],[5,"ovr_GetInt","","Reads an integer property.",null,null],[5,"ovr_SetInt","","Writes or creates an integer property.",null,null],[5,"ovr_GetFloat","","Reads a `f32` property.",null,null],[5,"ovr_SetFloat","","Writes or creates a `f32` property.",null,null],[5,"ovr_GetFloatArray","","Reads a `f32` array property.",null,null],[5,"ovr_SetFloatArray","","Writes or creates a `f32` array property.",null,null],[5,"ovr_GetString","","Reads a string property.",null,null],[5,"ovr_SetString","","Writes or creates a string property.",null,null],[5,"ovr_Detect","","Detects Oculus Runtime and Device Status",null,null],[5,"ovrMatrix4f_Projection","","Used to generate projection from `ovrEyeDesc::Fov`.",null,null],[5,"ovrTimewarpProjectionDesc_FromProjection","","Extracts the required data from the result of `ovrMatrix4f_Projection`.",null,null],[5,"ovrMatrix4f_OrthoSubProjection","","Generates an orthographic sub-projection.",null,null],[5,"ovr_CalcEyePoses","","Computes offset eye poses based on headPose returned by `ovrTrackingState`.",null,null],[5,"ovr_GetEyePoses","","Returns the predicted head pose in outHmdTrackingState and offset eye poses in outEyePoses.",null,null],[5,"ovrPosef_FlipHandedness","","Tracking poses provided by the SDK come in a right-handed coordinate system. If an application is passing in `ovrProjection_LeftHanded` into `ovrMatrix4f_Projection`, then it should also use this function to flip the HMD tracking poses to be left-handed.",null,null],[0,"opengl","","LibOVR functions for performing OpenGL interop.",null,null],[5,"ovr_CreateTextureSwapChainGL","ovr_sys::opengl","Creates a TextureSwapChain suitable for use with OpenGL.",null,null],[5,"ovr_GetTextureSwapChainBufferGL","","Get a specific buffer within the chain as a GL texture name",null,null],[5,"ovr_CreateMirrorTextureGL","","Creates a Mirror Texture which is auto-refreshed to mirror Rift contents produced by this application.",null,null],[5,"ovr_GetMirrorTextureBufferGL","","Get a the underlying buffer as a GL texture name",null,null],[0,"directx","ovr_sys","LibOVR functions for performing DirectX interop.",null,null],[5,"ovr_CreateTextureSwapChainDX","ovr_sys::directx","Create Texture Swap Chain suitable for use with Direct3D 11 and 12.",null,null],[5,"ovr_GetTextureSwapChainBufferDX","","Get a specific buffer within the chain as any compatible COM interface (similar to `QueryInterface`)",null,null],[5,"ovr_CreateMirrorTextureDX","","Create Mirror Texture which is auto-refreshed to mirror Rift contents produced by this application.",null,null],[5,"ovr_GetMirrorTextureBufferDX","","Get the underlying buffer as any compatible COM interface (similar to `QueryInterface`)",null,null],[0,"vulkan","ovr_sys","LibOVR functions for performing Vulkan interop.",null,null],[5,"ovr_GetSessionPhysicalDeviceVk","ovr_sys::vulkan","Find `PhysicalDevice` matching `ovrGraphicsLuid`",null,null],[5,"ovr_SetSynchonizationQueueVk","","Select `Queue` to block on till rendering is complete",null,null],[5,"ovr_CreateTextureSwapChainVk","","Create Texture Swap Chain suitable for use with Vulkan",null,null],[5,"ovr_GetTextureSwapChainBufferVk","","Get a specific `Image` within the chain",null,null],[5,"ovr_CreateMirrorTextureWithOptionsVk","","Create Mirror Texture which is auto-refreshed to mirror Rift contents produced by this application.",null,null],[5,"ovr_GetMirrorTextureBufferVk","","Get a the underlying mirror `Image`",null,null],[0,"audio","ovr_sys","LibOVR functions associated with audio functionality, including identifying audio devices and converting audio data into haptics data.",null,null],[3,"ovrAudioChannelData","ovr_sys::audio","Store audio PCM data (as 32b float samples) for an audio channel.",null,null],[12,"Samples","","Samples stored as floats [-1.0f, 1.0f].",37,null],[12,"SamplesCount","","Number of samples",37,null],[12,"Frequency","","Frequency (e.g. 44100)",37,null],[3,"ovrHapticsClip","","Store a full Haptics clip, which can be used as data source for multiple `ovrHapticsBuffer`s.",null,null],[12,"Samples","","Samples stored in opaque format",38,null],[12,"SamplesCount","","Number of samples",38,null],[5,"ovr_GetAudioDeviceOutWaveId","","Gets the ID of the preferred VR audio output device.",null,null],[5,"ovr_GetAudioDeviceInWaveId","","Gets the ID of the preferred VR audio input device.",null,null],[5,"ovr_GetAudioDeviceOutGuidStr","","Gets the GUID of the preferred VR audio device as a string.",null,null],[5,"ovr_GetAudioDeviceOutGuid","","Gets the GUID of the preferred VR audio device.",null,null],[5,"ovr_GetAudioDeviceInGuidStr","","Gets the GUID of the preferred VR microphone device as a string.",null,null],[5,"ovr_GetAudioDeviceInGuid","","Gets the GUID of the preferred VR microphone device.",null,null],[5,"ovr_ReadWavFromBuffer","","Reads an audio channel from Wav (Waveform Audio File) data. Input must be a byte buffer representing a valid Wav file. Audio samples from the specified channel are read, converted to float [-1.0f, 1.0f] and returned through `ovrAudioChannelData`.",null,null],[5,"ovr_GenHapticsFromAudioData","","Generates playable Touch Haptics data from an audio channel.",null,null],[5,"ovr_ReleaseAudioChannelData","","Releases memory allocated for `ovrAudioChannelData`. Must be called to avoid memory leak.",null,null],[5,"ovr_ReleaseHapticsClip","","Releases memory allocated for `ovrHapticsClip`. Must be called to avoid memory leak.",null,null],[6,"ovrHapticsGenMode","","Modes used to generate Touch Haptics from audio PCM buffer.",null,null],[17,"OVR_AUDIO_MAX_DEVICE_STR_SIZE","","",null,null],[17,"ovrHapticsGenMode_PointSample","","Point sample original signal at Haptics frequency",null,null],[17,"ovrHapticsGenMode_Count","","",null,null],[11,"clone","","",37,{"inputs":[{"name":"self"}],"output":{"name":"ovraudiochanneldata"}}],[11,"fmt","","",37,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",38,{"inputs":[{"name":"self"}],"output":{"name":"ovrhapticsclip"}}],[11,"fmt","","",38,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[6,"ovrResult","ovr_sys","API call results are represented at the highest level by a single `ovrResult`.",null,null],[6,"ovrSuccessType","","This is a general success result. Use  `OVR_SUCCESS` to test for success.",null,null],[6,"ovrSuccessTypes","","Success is a value greater or equal to 0, while all error types are negative values.",null,null],[6,"ovrErrorType","","Public error types",null,null],[6,"ovrBool","","Boolean type",null,null],[6,"ovrHmdType","","Enumerates all HMD types that we support.",null,null],[6,"ovrHmdCaps","","HMD capability bits reported by device.",null,null],[6,"ovrTrackingCaps","","Tracking capability bits reported by the device. Used with  `ovr_GetTrackingCaps`.",null,null],[6,"ovrEyeType","","Specifies which eye is being used for rendering. This type explicitly does not include a third \"NoStereo\" monoscopic option, as such is not required for an HMD-centered API.",null,null],[6,"ovrTrackingOrigin","","Specifies the coordinate system `ovrTrackingState` returns tracking poses in. Used with  `ovr_SetTrackingOriginType()`",null,null],[6,"ovrSession","","Used as an opaque pointer to an OVR session.",null,null],[6,"ovrStatusBits","","Bit flags describing the current status of sensor tracking.",null,null],[6,"ovrTrackerFlags","","Specifies sensor flags.",null,null],[6,"ovrTextureType","","The type of texture resource.",null,null],[6,"ovrTextureBindFlags","","The bindings required for texture swap chain.",null,null],[6,"ovrTextureFormat","","The format of a texture.",null,null],[6,"ovrTextureMiscFlags","","Misc flags overriding particular behaviors of a texture swap chain",null,null],[6,"ovrTextureSwapChain","","",null,null],[6,"ovrMirrorTexture","","",null,null],[6,"ovrButton","","Describes button input types. Button inputs are combined; that is they will be reported as pressed if they are pressed on either one of the two devices. The `ovrButton_Up`/Down/Left/Right map to both XBox D-Pad and directional buttons. The `ovrButton_Enter` and `ovrButton_Return` map to Start and Back controller buttons, respectively.",null,null],[6,"ovrTouch","","Describes touch input types. These values map to capacitive touch values reported `ovrInputState`::Touch. Some of these values are mapped to button bits for consistency.",null,null],[6,"ovrControllerType","","Specifies which controller is connected; multiple can be connected at once.",null,null],[6,"ovrHapticsBufferSubmitMode","","Haptics buffer submit mode",null,null],[6,"ovrTrackedDeviceType","","Position tracked devices",null,null],[6,"ovrBoundaryType","","Boundary types that specified while using the boundary system",null,null],[6,"ovrHandType","","Provides names for the left and right hand array indexes.",null,null],[6,"ovrInitFlags","","Initialization flags.",null,null],[6,"ovrLogLevel","","Logging levels",null,null],[6,"ovrLogCallback","","Signature of the logging callback function pointer type.",null,null],[6,"ovrLayerType","","Each layer type has an associated struct, such as `ovrLayerEyeFov`.",null,null],[6,"ovrLayerFlags","","Identifies flags used by `ovrLayerHeader` and which are passed to `ovr_SubmitFrame`.",null,null],[6,"ovrPerfHudMode","","Performance HUD enables the HMD user to see information critical to the real-time operation of the VR application such as latency timing, and CPU & GPU performance metrics",null,null],[6,"ovrLayerHudMode","","Layer HUD enables the HMD user to see information about a layer",null,null],[6,"ovrDebugHudStereoMode","","Debug HUD is provided to help developers gauge and debug the fidelity of their app's stereo rendering characteristics. Using the provided quad and crosshair guides, the developer can verify various aspects such as VR tracking units (e.g. meters), stereo camera-parallax properties (e.g. making sure objects at infinity are rendered with the proper separation), measuring VR geometry sizes and distances and more.",null,null],[6,"ovrProjectionModifier","","Enumerates modifications to the projection matrix based on the application's needs.",null,null],[17,"OVR_PRODUCT_VERSION","","",null,null],[17,"OVR_MAJOR_VERSION","","",null,null],[17,"OVR_MINOR_VERSION","","",null,null],[17,"OVR_BUILD_VERSION","","",null,null],[17,"OVR_KEY_USER","","",null,null],[17,"OVR_KEY_NAME","","",null,null],[17,"OVR_KEY_GENDER","","",null,null],[17,"OVR_DEFAULT_GENDER","","",null,null],[17,"OVR_KEY_PLAYER_HEIGHT","","",null,null],[17,"OVR_DEFAULT_PLAYER_HEIGHT","","",null,null],[17,"OVR_KEY_EYE_HEIGHT","","",null,null],[17,"OVR_DEFAULT_EYE_HEIGHT","","",null,null],[17,"OVR_KEY_NECK_TO_EYE_DISTANCE","","",null,null],[17,"OVR_DEFAULT_NECK_TO_EYE_HORIZONTAL","","",null,null],[17,"OVR_DEFAULT_NECK_TO_EYE_VERTICAL","","",null,null],[17,"OVR_KEY_EYE_TO_NOSE_DISTANCE","","",null,null],[17,"OVR_PERF_HUD_MODE","","",null,null],[17,"OVR_LAYER_HUD_MODE","","",null,null],[17,"OVR_LAYER_HUD_CURRENT_LAYER","","",null,null],[17,"OVR_LAYER_HUD_SHOW_ALL_LAYERS","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_MODE","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_GUIDE_INFO_ENABLE","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_GUIDE_SIZE","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_GUIDE_POSITION","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_GUIDE_YAWPITCHROLL","","",null,null],[17,"OVR_DEBUG_HUD_STEREO_GUIDE_COLOR","","",null,null],[17,"ovrSuccess","","",null,null],[17,"ovrSuccess_NotVisible","","Returned from a call to SubmitFrame. The call succeeded, but what the app rendered will not be visible on the HMD. Ideally the app should continue calling SubmitFrame, but not do any rendering. When the result becomes `ovrSuccess`, rendering should continue as usual.",null,null],[17,"ovrSuccess_BoundaryInvalid","","Boundary is invalid due to sensor change or was not setup.",null,null],[17,"ovrSuccess_DeviceUnavailable","","Device is not available for the requested operation.",null,null],[17,"ovrError_MemoryAllocationFailure","","Failure to allocate memory.",null,null],[17,"ovrError_InvalidSession","","Invalid `ovrSession` parameter provided.",null,null],[17,"ovrError_Timeout","","The operation timed out.",null,null],[17,"ovrError_NotInitialized","","The system or component has not been initialized.",null,null],[17,"ovrError_InvalidParameter","","Invalid parameter provided. See error info or log for details.",null,null],[17,"ovrError_ServiceError","","Generic service error. See error info or log for details.",null,null],[17,"ovrError_NoHmd","","The given HMD doesn't exist.",null,null],[17,"ovrError_Unsupported","","Function call is not supported on this hardware/software",null,null],[17,"ovrError_DeviceUnavailable","","Specified device type isn't available.",null,null],[17,"ovrError_InvalidHeadsetOrientation","","The headset was in an invalid orientation for the requested operation (e.g. vertically oriented during  `ovr_RecenterPose`).",null,null],[17,"ovrError_ClientSkippedDestroy","","The client failed to call `ovr_Destroy` on an active session before calling  `ovr_Shutdown`. Or the client crashed.",null,null],[17,"ovrError_ClientSkippedShutdown","","The client failed to call  `ovr_Shutdown` or the client crashed.",null,null],[17,"ovrError_ServiceDeadlockDetected","","The service watchdog discovered a deadlock.",null,null],[17,"ovrError_InvalidOperation","","Function call is invalid for object's current state",null,null],[17,"ovrError_AudioDeviceNotFound","","Failure to find the specified audio device.",null,null],[17,"ovrError_AudioComError","","Generic COM error.",null,null],[17,"ovrError_Initialize","","Generic initialization error.",null,null],[17,"ovrError_LibLoad","","Couldn't load LibOVRRT.",null,null],[17,"ovrError_LibVersion","","LibOVRRT version incompatibility.",null,null],[17,"ovrError_ServiceConnection","","Couldn't connect to the OVR Service.",null,null],[17,"ovrError_ServiceVersion","","OVR Service version incompatibility.",null,null],[17,"ovrError_IncompatibleOS","","The operating system version is incompatible.",null,null],[17,"ovrError_DisplayInit","","Unable to initialize the HMD display.",null,null],[17,"ovrError_ServerStart","","Unable to start the server. Is it already running?",null,null],[17,"ovrError_Reinitialization","","Attempting to re-initialize with a different version.",null,null],[17,"ovrError_MismatchedAdapters","","Chosen rendering adapters between client and service do not match",null,null],[17,"ovrError_LeakingResources","","Calling application has leaked resources",null,null],[17,"ovrError_ClientVersion","","Client version too old to connect to service",null,null],[17,"ovrError_OutOfDateOS","","The operating system is out of date.",null,null],[17,"ovrError_OutOfDateGfxDriver","","The graphics driver is out of date.",null,null],[17,"ovrError_IncompatibleGPU","","The graphics hardware is not supported",null,null],[17,"ovrError_NoValidVRDisplaySystem","","No valid VR display system found.",null,null],[17,"ovrError_Obsolete","","Feature or API is obsolete and no longer supported.",null,null],[17,"ovrError_DisabledOrDefaultAdapter","","No supported VR display system found, but disabled or driverless adapter found.",null,null],[17,"ovrError_HybridGraphicsNotSupported","","The system is using hybrid graphics (Optimus, etc...), which is not support.",null,null],[17,"ovrError_DisplayManagerInit","","Initialization of the DisplayManager failed.",null,null],[17,"ovrError_TrackerDriverInit","","Failed to get the interface for an attached tracker",null,null],[17,"ovrError_LibSignCheck","","LibOVRRT signature check failure.",null,null],[17,"ovrError_LibPath","","LibOVRRT path failure.",null,null],[17,"ovrError_LibSymbols","","LibOVRRT symbol resolution failure.",null,null],[17,"ovrError_RemoteSession","","Failed to connect to the service because remote connections to the service are not allowed.",null,null],[17,"ovrError_DisplayLost","","In the event of a system-wide graphics reset or cable unplug this is returned to the app.",null,null],[17,"ovrError_TextureSwapChainFull","","`ovr_CommitTextureSwapChain` was called too many times on a texture swapchain without calling submit to use the chain.",null,null],[17,"ovrError_TextureSwapChainInvalid","","The `ovrTextureSwapChain` is in an incomplete or inconsistent state. Ensure  `ovr_CommitTextureSwapChain` was called at least once first.",null,null],[17,"ovrError_GraphicsDeviceReset","","Graphics device has been reset (TDR, etc...)",null,null],[17,"ovrError_DisplayRemoved","","HMD removed from the display adapter",null,null],[17,"ovrError_ContentProtectionNotAvailable","","Content protection is not available for the display",null,null],[17,"ovrError_ApplicationInvisible","","Application declared itself as an invisible type and is not allowed to submit frames.",null,null],[17,"ovrError_Disallowed","","The given request is disallowed under the current conditions.",null,null],[17,"ovrError_DisplayPluggedIncorrectly","","Display portion of HMD is plugged into an incompatible port (ex: IGP)",null,null],[17,"ovrError_RuntimeException","","A runtime exception occurred. The application is required to shutdown LibOVR and re-initialize it before this error state will be cleared.",null,null],[17,"ovrError_NoCalibration","","Result of a missing calibration block",null,null],[17,"ovrError_OldVersion","","Result of an old calibration block",null,null],[17,"ovrError_MisformattedBlock","","Result of a bad calibration block due to lengths",null,null],[17,"ovrFalse","","`ovrBool` value of false.",null,null],[17,"ovrTrue","","`ovrBool` value of true.",null,null],[17,"ovrHmd_None","","",null,null],[17,"ovrHmd_DK1","","",null,null],[17,"ovrHmd_DKHD","","",null,null],[17,"ovrHmd_DK2","","",null,null],[17,"ovrHmd_CB","","",null,null],[17,"ovrHmd_Other","","",null,null],[17,"ovrHmd_E3_2015","","",null,null],[17,"ovrHmd_ES06","","",null,null],[17,"ovrHmd_ES09","","",null,null],[17,"ovrHmd_ES11","","",null,null],[17,"ovrHmd_CV1","","",null,null],[17,"ovrHmdCap_DebugDevice","","(read only) Specifies that the HMD is a virtual debug device.",null,null],[17,"ovrTrackingCap_Orientation","","Supports orientation tracking (IMU).",null,null],[17,"ovrTrackingCap_MagYawCorrection","","Supports yaw drift correction via a magnetometer or other means.",null,null],[17,"ovrTrackingCap_Position","","Supports positional tracking.",null,null],[17,"ovrEye_Left","","The left eye, from the viewer's perspective.",null,null],[17,"ovrEye_Right","","The right eye, from the viewer's perspective.",null,null],[17,"ovrEye_Count","","\\internal Count of enumerated elements.",null,null],[17,"ovrTrackingOrigin_EyeLevel","","Tracking system origin reported at eye (HMD) height",null,null],[17,"ovrTrackingOrigin_FloorLevel","","Tracking system origin reported at floor height",null,null],[17,"ovrStatus_OrientationTracked","","Orientation is currently tracked (connected and in use).",null,null],[17,"ovrStatus_PositionTracked","","Position is currently tracked (false if out of range).",null,null],[17,"ovrTracker_Connected","","The sensor is present, else the sensor is absent or offline.",null,null],[17,"ovrTracker_PoseTracked","","The sensor has a valid pose, else the pose is unavailable. This will only be set if `ovrTracker_Connected` is set.",null,null],[17,"ovrTexture_2D","","2D textures.",null,null],[17,"ovrTexture_2D_External","","External 2D texture. Not used on PC",null,null],[17,"ovrTexture_Cube","","Cube maps. Not currently supported on PC.",null,null],[17,"ovrTexture_Count","","",null,null],[17,"ovrTextureBind_None","","",null,null],[17,"ovrTextureBind_DX_RenderTarget","","The application can write into the chain with pixel shader",null,null],[17,"ovrTextureBind_DX_UnorderedAccess","","The application can write to the chain with compute shader",null,null],[17,"ovrTextureBind_DX_DepthStencil","","The chain buffers can be bound as depth and/or stencil buffers",null,null],[17,"OVR_FORMAT_UNKNOWN","","",null,null],[17,"OVR_FORMAT_B5G6R5_UNORM","","Not currently supported on PC. Would require a DirectX 11.1 device.",null,null],[17,"OVR_FORMAT_B5G5R5A1_UNORM","","Not currently supported on PC. Would require a DirectX 11.1 device.",null,null],[17,"OVR_FORMAT_B4G4R4A4_UNORM","","Not currently supported on PC. Would require a DirectX 11.1 device.",null,null],[17,"OVR_FORMAT_R8G8B8A8_UNORM","","",null,null],[17,"OVR_FORMAT_R8G8B8A8_UNORM_SRGB","","",null,null],[17,"OVR_FORMAT_B8G8R8A8_UNORM","","",null,null],[17,"OVR_FORMAT_B8G8R8A8_UNORM_SRGB","","Not supported for OpenGL applications",null,null],[17,"OVR_FORMAT_B8G8R8X8_UNORM","","Not supported for OpenGL applications",null,null],[17,"OVR_FORMAT_B8G8R8X8_UNORM_SRGB","","Not supported for OpenGL applications",null,null],[17,"OVR_FORMAT_R16G16B16A16_FLOAT","","",null,null],[17,"OVR_FORMAT_R11G11B10_FLOAT","","Introduced in v1.10",null,null],[17,"OVR_FORMAT_D16_UNORM","","",null,null],[17,"OVR_FORMAT_D24_UNORM_S8_UINT","","",null,null],[17,"OVR_FORMAT_D32_FLOAT","","",null,null],[17,"OVR_FORMAT_D32_FLOAT_S8X24_UINT","","",null,null],[17,"OVR_FORMAT_BC1_UNORM","","",null,null],[17,"OVR_FORMAT_BC1_UNORM_SRGB","","",null,null],[17,"OVR_FORMAT_BC2_UNORM","","",null,null],[17,"OVR_FORMAT_BC2_UNORM_SRGB","","",null,null],[17,"OVR_FORMAT_BC3_UNORM","","",null,null],[17,"OVR_FORMAT_BC3_UNORM_SRGB","","",null,null],[17,"OVR_FORMAT_BC6H_UF16","","",null,null],[17,"OVR_FORMAT_BC6H_SF16","","",null,null],[17,"OVR_FORMAT_BC7_UNORM","","",null,null],[17,"OVR_FORMAT_BC7_UNORM_SRGB","","",null,null],[17,"ovrTextureMisc_None","","",null,null],[17,"ovrTextureMisc_DX_Typeless","","DX only: The underlying texture is created with a TYPELESS equivalent of the format specified in the texture desc. The SDK will still access the texture using the format specified in the texture desc, but the app can create views with different formats if this is specified.",null,null],[17,"ovrTextureMisc_AllowGenerateMips","","DX only: Allow generation of the mip chain on the GPU via the GenerateMips call. This flag requires that RenderTarget binding also be specified.",null,null],[17,"ovrTextureMisc_ProtectedContent","","Texture swap chain contains protected content, and requires HDCP connection in order to display to HMD. Also prevents mirroring or other redirection of any frame containing this contents",null,null],[17,"ovrButton_A","","A button on XBox controllers and right Touch controller. Select button on Oculus Remote.",null,null],[17,"ovrButton_B","","B button on XBox controllers and right Touch controller. Back button on Oculus Remote.",null,null],[17,"ovrButton_RThumb","","Right thumbstick on XBox controllers and Touch controllers. Not present on Oculus Remote.",null,null],[17,"ovrButton_RShoulder","","Right shoulder button on XBox controllers. Not present on Touch controllers or Oculus Remote.",null,null],[17,"ovrButton_X","","X button on XBox controllers and left Touch controller. Not present on Oculus Remote.",null,null],[17,"ovrButton_Y","","Y button on XBox controllers and left Touch controller. Not present on Oculus Remote.",null,null],[17,"ovrButton_LThumb","","Left thumbstick on XBox controllers and Touch controllers. Not present on Oculus Remote.",null,null],[17,"ovrButton_LShoulder","","Left shoulder button on XBox controllers. Not present on Touch controllers or Oculus Remote.",null,null],[17,"ovrButton_Up","","Up button on XBox controllers and Oculus Remote. Not present on Touch controllers.",null,null],[17,"ovrButton_Down","","Down button on XBox controllers and Oculus Remote. Not present on Touch controllers.",null,null],[17,"ovrButton_Left","","Left button on XBox controllers and Oculus Remote. Not present on Touch controllers.",null,null],[17,"ovrButton_Right","","Right button on XBox controllers and Oculus Remote. Not present on Touch controllers.",null,null],[17,"ovrButton_Enter","","Start on XBox 360 controller. Menu on XBox One controller and Left Touch controller. Should be referred to as the Menu button in user-facing documentation.",null,null],[17,"ovrButton_Back","","Back on Xbox 360 controller. View button on XBox One controller. Not present on Touch controllers or Oculus Remote.",null,null],[17,"ovrButton_VolUp","","Volume button on Oculus Remote. Not present on XBox or Touch controllers.",null,null],[17,"ovrButton_VolDown","","Volume button on Oculus Remote. Not present on XBox or Touch controllers.",null,null],[17,"ovrButton_Home","","Home button on XBox controllers. Oculus button on Touch controllers and Oculus Remote.",null,null],[17,"ovrButton_Private","","Bit mask of all buttons that are for private usage by Oculus",null,null],[17,"ovrButton_RMask","","Bit mask of all buttons on the right Touch controller",null,null],[17,"ovrButton_LMask","","Bit mask of all buttons on the left Touch controller",null,null],[17,"ovrTouch_A","","",null,null],[17,"ovrTouch_B","","",null,null],[17,"ovrTouch_RThumb","","",null,null],[17,"ovrTouch_RThumbRest","","",null,null],[17,"ovrTouch_RIndexTrigger","","",null,null],[17,"ovrTouch_RButtonMask","","Bit mask of all the button touches on the right controller",null,null],[17,"ovrTouch_X","","",null,null],[17,"ovrTouch_Y","","",null,null],[17,"ovrTouch_LThumb","","",null,null],[17,"ovrTouch_LThumbRest","","",null,null],[17,"ovrTouch_LIndexTrigger","","",null,null],[17,"ovrTouch_LButtonMask","","Bit mask of all the button touches on the left controller",null,null],[17,"ovrTouch_RIndexPointing","","Finger pose state Derived internally based on distance, proximity to sensors and filtering.",null,null],[17,"ovrTouch_RThumbUp","","",null,null],[17,"ovrTouch_LIndexPointing","","",null,null],[17,"ovrTouch_LThumbUp","","",null,null],[17,"ovrTouch_RPoseMask","","Bit mask of all right controller poses",null,null],[17,"ovrTouch_LPoseMask","","Bit mask of all left controller poses",null,null],[17,"ovrControllerType_None","","",null,null],[17,"ovrControllerType_LTouch","","",null,null],[17,"ovrControllerType_RTouch","","",null,null],[17,"ovrControllerType_Touch","","",null,null],[17,"ovrControllerType_Remote","","",null,null],[17,"ovrControllerType_XBox","","",null,null],[17,"ovrControllerType_Active","","Operate on or query whichever controller is active.",null,null],[17,"ovrHapticsBufferSubmit_Enqueue","","Enqueue buffer for later playback",null,null],[17,"ovrTrackedDevice_HMD","","",null,null],[17,"ovrTrackedDevice_LTouch","","",null,null],[17,"ovrTrackedDevice_RTouch","","",null,null],[17,"ovrTrackedDevice_Touch","","",null,null],[17,"ovrTrackedDevice_All","","",null,null],[17,"ovrBoundary_Outer","","Outer boundary - closely represents user setup walls",null,null],[17,"ovrBoundary_PlayArea","","Play area - safe rectangular area inside outer boundary which can optionally be used to restrict user interactions and motion.",null,null],[17,"ovrHand_Left","","",null,null],[17,"ovrHand_Right","","",null,null],[17,"ovrHand_Count","","",null,null],[17,"ovrInit_Debug","","When a debug library is requested, a slower debugging version of the library will run which can be used to help solve problems in the library and debug application code.",null,null],[17,"ovrInit_RequestVersion","","When a version is requested, the LibOVR runtime respects the RequestedMinorVersion field and verifies that the RequestedMinorVersion is supported. Normally when you specify this flag you simply use  `OVR_MINOR_VERSION` for `ovrInitParams`::RequestedMinorVersion, though you could use a lower version than  `OVR_MINOR_VERSION` to specify previous version behavior.",null,null],[17,"ovrinit_WritableBits","","These bits are writable by user code.",null,null],[17,"ovrLogLevel_Debug","","Debug-level log event.",null,null],[17,"ovrLogLevel_Info","","Info-level log event.",null,null],[17,"ovrLogLevel_Error","","Error-level log event.",null,null],[17,"ovrMaxLayerCount","","Specifies the maximum number of layers supported by `ovr_SubmitFrame`.",null,null],[17,"ovrLayerType_Disabled","","Layer is disabled.",null,null],[17,"ovrLayerType_EyeFov","","Described by `ovrLayerEyeFov`.",null,null],[17,"ovrLayerType_Quad","","Described by `ovrLayerQuad`. Previously called `ovrLayerType_QuadInWorld`.",null,null],[17,"ovrLayerType_EyeMatrix","","Described by `ovrLayerEyeMatrix`.",null,null],[17,"ovrLayerFlag_HighQuality","","`ovrLayerFlag_HighQuality` enables 4x anisotropic sampling during the composition of the layer.",null,null],[17,"ovrLayerFlag_TextureOriginAtBottomLeft","","`ovrLayerFlag_TextureOriginAtBottomLeft`: the opposite is TopLeft. Generally this is false for D3D, true for OpenGL.",null,null],[17,"ovrLayerFlag_HeadLocked","","Mark this surface as \"headlocked\", which means it is specified relative to the HMD and moves with it, rather than being specified relative to sensor/torso space and remaining still while the head moves.",null,null],[17,"ovrMaxProvidedFrameStats","","",null,null],[17,"ovrPerfHud_Off","","Turns off the performance HUD",null,null],[17,"ovrPerfHud_PerfSummary","","Shows performance summary and headroom",null,null],[17,"ovrPerfHud_LatencyTiming","","Shows latency related timing info",null,null],[17,"ovrPerfHud_AppRenderTiming","","Shows render timing info for application",null,null],[17,"ovrPerfHud_CompRenderTiming","","Shows render timing info for OVR compositor",null,null],[17,"ovrPerfHud_VersionInfo","","Shows SDK & HMD version Info",null,null],[17,"ovrLayerHud_Off","","Turns off the layer HUD",null,null],[17,"ovrLayerHud_Info","","Shows info about a specific layer",null,null],[17,"ovrDebugHudStereo_Off","","Turns off the Stereo Debug HUD",null,null],[17,"ovrDebugHudStereo_Quad","","Renders Quad in world for Stereo Debugging",null,null],[17,"ovrDebugHudStereo_QuadWithCrosshair","","Renders Quad+crosshair in world for Stereo Debugging",null,null],[17,"ovrDebugHudStereo_CrosshairAtInfinity","","Renders screen-space crosshair at infinity for Stereo Debugging",null,null],[17,"ovrProjection_None","","Use for generating a default projection matrix that is:",null,null],[17,"ovrProjection_LeftHanded","","Enable if using left-handed transformations in your application.",null,null],[17,"ovrProjection_FarLessThanNear","","After the projection transform is applied, far values stored in the depth buffer will be less than closer depth values. NOTE: Enable only if the application is using a floating-point depth buffer for proper precision.",null,null],[17,"ovrProjection_FarClipAtInfinity","","When this flag is used, the zfar value pushed into `ovrMatrix4f_Projection()` will be ignored NOTE: Enable only if `ovrProjection_FarLessThanNear` is also enabled where the far clipping plane will be pushed to infinity.",null,null],[17,"ovrProjection_ClipRangeOpenGL","","Enable if the application is rendering with OpenGL and expects a projection matrix with a clipping range of (-w to w). Ignore this flag if your application already handles the conversion from D3D range (0 to w) to OpenGL.",null,null],[11,"clone","","",0,{"inputs":[{"name":"self"}],"output":{"name":"ovrerrorinfo"}}],[11,"fmt","","",0,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",1,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",1,{"inputs":[{"name":"self"}],"output":{"name":"ovrcolorf"}}],[11,"fmt","","",2,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",2,{"inputs":[{"name":"self"}],"output":{"name":"ovrvector2i"}}],[11,"fmt","","",3,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",3,{"inputs":[{"name":"self"}],"output":{"name":"ovrsizei"}}],[11,"fmt","","",4,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",4,{"inputs":[{"name":"self"}],"output":{"name":"ovrrecti"}}],[11,"fmt","","",5,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",5,{"inputs":[{"name":"self"}],"output":{"name":"ovrquatf"}}],[11,"fmt","","",6,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",6,{"inputs":[{"name":"self"}],"output":{"name":"ovrvector2f"}}],[11,"fmt","","",7,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",7,{"inputs":[{"name":"self"}],"output":{"name":"ovrvector3f"}}],[11,"fmt","","",8,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",8,{"inputs":[{"name":"self"}],"output":{"name":"ovrmatrix4f"}}],[11,"fmt","","",9,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",9,{"inputs":[{"name":"self"}],"output":{"name":"ovrposef"}}],[11,"fmt","","",10,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",10,{"inputs":[{"name":"self"}],"output":{"name":"ovrposestatef"}}],[11,"fmt","","",11,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",11,{"inputs":[{"name":"self"}],"output":{"name":"ovrfovport"}}],[11,"fmt","","",12,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",12,{"inputs":[{"name":"self"}],"output":{"name":"ovrgraphicsluid"}}],[11,"clone","","",13,{"inputs":[{"name":"self"}],"output":{"name":"ovrhmddesc"}}],[11,"fmt","","",14,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",14,{"inputs":[{"name":"self"}],"output":{"name":"ovrtrackerdesc"}}],[11,"fmt","","",15,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",15,{"inputs":[{"name":"self"}],"output":{"name":"ovrtrackerpose"}}],[11,"fmt","","",16,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",16,{"inputs":[{"name":"self"}],"output":{"name":"ovrtrackingstate"}}],[11,"fmt","","",17,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",17,{"inputs":[{"name":"self"}],"output":{"name":"ovreyerenderdesc"}}],[11,"fmt","","",18,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",18,{"inputs":[{"name":"self"}],"output":{"name":"ovrtimewarpprojectiondesc"}}],[11,"fmt","","",19,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",19,{"inputs":[{"name":"self"}],"output":{"name":"ovrviewscaledesc"}}],[11,"fmt","","",20,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",20,{"inputs":[{"name":"self"}],"output":{"name":"ovrtextureswapchaindesc"}}],[11,"fmt","","",21,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",21,{"inputs":[{"name":"self"}],"output":{"name":"ovrmirrortexturedesc"}}],[11,"fmt","","",22,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",22,{"inputs":[{"name":"self"}],"output":{"name":"ovrtouchhapticsdesc"}}],[11,"fmt","","",23,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",23,{"inputs":[{"name":"self"}],"output":{"name":"ovrhapticsbuffer"}}],[11,"fmt","","",24,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",24,{"inputs":[{"name":"self"}],"output":{"name":"ovrhapticsplaybackstate"}}],[11,"fmt","","",25,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",25,{"inputs":[{"name":"self"}],"output":{"name":"ovrboundarylookandfeel"}}],[11,"fmt","","",26,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",26,{"inputs":[{"name":"self"}],"output":{"name":"ovrboundarytestresult"}}],[11,"fmt","","",27,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",27,{"inputs":[{"name":"self"}],"output":{"name":"ovrinputstate"}}],[11,"fmt","","",28,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",28,{"inputs":[{"name":"self"}],"output":{"name":"ovrinitparams"}}],[11,"fmt","","",29,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",29,{"inputs":[{"name":"self"}],"output":{"name":"ovrsessionstatus"}}],[11,"fmt","","",30,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",30,{"inputs":[{"name":"self"}],"output":{"name":"ovrlayerheader"}}],[11,"fmt","","",31,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",31,{"inputs":[{"name":"self"}],"output":{"name":"ovrlayereyefov"}}],[11,"fmt","","",32,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",32,{"inputs":[{"name":"self"}],"output":{"name":"ovrlayereyematrix"}}],[11,"fmt","","",33,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",33,{"inputs":[{"name":"self"}],"output":{"name":"ovrlayerquad"}}],[11,"fmt","","",34,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",34,{"inputs":[{"name":"self"}],"output":{"name":"ovrperfstatspercompositorframe"}}],[11,"fmt","","",35,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",35,{"inputs":[{"name":"self"}],"output":{"name":"ovrperfstats"}}],[11,"clone","","",36,{"inputs":[{"name":"self"}],"output":{"name":"ovrdetectresult"}}],[11,"fmt","","",36,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}]],"paths":[[3,"ovrErrorInfo"],[3,"ovrColorf"],[3,"ovrVector2i"],[3,"ovrSizei"],[3,"ovrRecti"],[3,"ovrQuatf"],[3,"ovrVector2f"],[3,"ovrVector3f"],[3,"ovrMatrix4f"],[3,"ovrPosef"],[3,"ovrPoseStatef"],[3,"ovrFovPort"],[3,"ovrGraphicsLuid"],[3,"ovrHmdDesc"],[3,"ovrTrackerDesc"],[3,"ovrTrackerPose"],[3,"ovrTrackingState"],[3,"ovrEyeRenderDesc"],[3,"ovrTimewarpProjectionDesc"],[3,"ovrViewScaleDesc"],[3,"ovrTextureSwapChainDesc"],[3,"ovrMirrorTextureDesc"],[3,"ovrTouchHapticsDesc"],[3,"ovrHapticsBuffer"],[3,"ovrHapticsPlaybackState"],[3,"ovrBoundaryLookAndFeel"],[3,"ovrBoundaryTestResult"],[3,"ovrInputState"],[3,"ovrInitParams"],[3,"ovrSessionStatus"],[3,"ovrLayerHeader"],[3,"ovrLayerEyeFov"],[3,"ovrLayerEyeMatrix"],[3,"ovrLayerQuad"],[3,"ovrPerfStatsPerCompositorFrame"],[3,"ovrPerfStats"],[3,"ovrDetectResult"],[3,"ovrAudioChannelData"],[3,"ovrHapticsClip"]]};
initSearch(searchIndex);
